# this is only the root output_dir
output_dir: models/chess-gpt2-uci-12x12x768-probes

# Config Arguments:
state_fn_name: to_piece_by_color
chess_model: austindavis/chess-gpt2-uci-12x12x768
dataset_repo_id: austindavis/chess-gpt2-hiddenstates-768
wandb_project: probe_training_768
layer: 2
phase: 0

# # Post-hoc Eval-only settings:
# do_train: false
# run_id: x564ogz6
# pretrain_checkpoint: models/chess-gpt2-uci-12x12x768-probes/to_piece_by_color/layer-0/phase-0/checkpoint-575

# TrainingArguments
num_train_epochs: 15
per_device_train_batch_size: 2000
per_device_eval_batch_size: 32
weight_decay: 0.01
save_total_limit: 1
save_safetensors: true
overwrite_output_dir: true
metric_for_best_model: loss
logging_dir: ./logs
logging_steps: 25
evaluation_strategy: steps
eval_steps: 10
save_strategy: "no"
use_cpu: false
lr_scheduler_type: cosine
learning_rate: 0.009
torch_compile: true

# Reporting/publishing
report_to: wandb
push_to_hub: false
